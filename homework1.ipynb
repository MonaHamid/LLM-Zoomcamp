{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48186d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '1f08c3fad565', 'cluster_name': 'docker-cluster', 'cluster_uuid': '3SEmyz2SRRO-Z0vJO3tigA', 'version': {'number': '8.17.6', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'dbcbbbd0bc4924cfeb28929dc05d82d662c527b7', 'build_date': '2025-04-30T14:07:12.231372970Z', 'build_snapshot': False, 'lucene_version': '9.12.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch(\"http://localhost:9200\")\n",
    "print(es_client.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b62fe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"1f08c3fad565\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"3SEmyz2SRRO-Z0vJO3tigA\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"8.17.6\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"dbcbbbd0bc4924cfeb28929dc05d82d662c527b7\",\n",
      "    \"build_date\" : \"2025-04-30T14:07:12.231372970Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"9.12.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl localhost:9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c68260c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d0a0d9",
   "metadata": {},
   "source": [
    "Q2 Indexing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1899a961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted index: course-questions\n",
      " Index created.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, NotFoundError\n",
    "\n",
    "es_client = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Delete if exists\n",
    "try:\n",
    "    es_client.indices.delete(index=index_name)\n",
    "    print(f\"Deleted index: {index_name}\")\n",
    "except NotFoundError:\n",
    "    print(\"Index not found, skipping delete.\")\n",
    "\n",
    "# Create the index\n",
    "es_client.indices.create(\n",
    "    index=index_name,\n",
    "    settings=index_settings[\"settings\"],\n",
    "    mappings=index_settings[\"mappings\"]\n",
    ")\n",
    "print(\" Index created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde1a140",
   "metadata": {},
   "source": [
    "Answer 2: Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db6972",
   "metadata": {},
   "source": [
    "Q3 Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2260bcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_source': {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I debug a docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'},\n",
       "  '_score': 84.050095},\n",
       " {'_source': {'text': 'In case running pgcli  locally causes issues or you do not want to install it locally you can use it running in a Docker container instead.\\nBelow the usage with values used in the videos of the course for:\\nnetwork name (docker network)\\npostgres related variables for pgcli\\nHostname\\nUsername\\nPort\\nDatabase name\\n$ docker run -it --rm --network pg-network ai2ys/dockerized-pgcli:4.0.1\\n175dd47cda07:/# pgcli -h pg-database -U root -p 5432 -d ny_taxi\\nPassword for root:\\nServer: PostgreSQL 16.1 (Debian 16.1-1.pgdg120+1)\\nVersion: 4.0.1\\nHome: http://pgcli.com\\nroot@pg-database:ny_taxi> \\\\dt\\n+--------+------------------+-------+-------+\\n| Schema | Name             | Type  | Owner |\\n|--------+------------------+-------+-------|\\n| public | yellow_taxi_data | table | root  |\\n+--------+------------------+-------+-------+\\nSELECT 1\\nTime: 0.009s\\nroot@pg-database:ny_taxi>',\n",
       "   'section': 'Module 1: Docker and Terraform',\n",
       "   'question': 'PGCLI - running in a Docker container',\n",
       "   'course': 'data-engineering-zoomcamp'},\n",
       "  '_score': 75.54128},\n",
       " {'_source': {'text': 'If you are trying to run Flask gunicorn & MLFlow server from the same container, defining both in Dockerfile with CMD will only run MLFlow & not Flask.\\nSolution: Create separate shell script with server run commands, for eg:\\n> \\tscript1.sh\\n#!/bin/bash\\ngunicorn --bind=0.0.0.0:9696 predict:app\\nAnother script with e.g. MLFlow server:\\n>\\tscript2.sh\\n#!/bin/bash\\nmlflow server -h 0.0.0.0 -p 5000 --backend-store-uri=sqlite:///mlflow.db --default-artifact-root=g3://zc-bucket/mlruns/\\nCreate a wrapper script to run above 2 scripts:\\n>\\twrapper_script.sh\\n#!/bin/bash\\n# Start the first process\\n./script1.sh &\\n# Start the second process\\n./script2.sh &\\n# Wait for any process to exit\\nwait -n\\n# Exit with status of process that exited first\\nexit $?\\nGive executable permissions to all scripts:\\nchmod +x *.sh\\nNow we can define last line of Dockerfile as:\\n> \\tDockerfile\\nCMD ./wrapper_script.sh\\nDont forget to expose all ports defined by services!',\n",
       "   'section': 'Module 4: Deployment',\n",
       "   'question': 'Running multiple services in a Docker container',\n",
       "   'course': 'mlops-zoomcamp'},\n",
       "  '_score': 72.08518},\n",
       " {'_source': {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\",\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I copy files from my local machine to docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'},\n",
       "  '_score': 51.04628},\n",
       " {'_source': {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I copy files from a different folder into docker container’s working directory?',\n",
       "   'course': 'machine-learning-zoomcamp'},\n",
       "  '_score': 49.938507}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do I execute a command in a running docker container?\"\n",
    "\n",
    "def elastic_search(query):\n",
    "    \n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Searhing using the query\n",
    "    response = es_client.search(index=index_name,body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append({\n",
    "            \"_source\": hit['_source'],\n",
    "            \"_score\": hit['_score']\n",
    "        })\n",
    "\n",
    "    return result_docs\n",
    "\n",
    "elastic_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c97996",
   "metadata": {},
   "source": [
    "Answer 3: 84.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf7bbf0",
   "metadata": {},
   "source": [
    "Q4 Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6de85e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I debug a docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\",\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I copy files from my local machine to docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I copy files from a different folder into docker container’s working directory?',\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def elastic_search_filtered(query):\n",
    "    \n",
    "    search_query = {\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Searhing using the query\n",
    "    response = es_client.search(index=index_name,body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n",
    "\n",
    "elastic_search_filtered(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610a24f1",
   "metadata": {},
   "source": [
    "Answer 4 :How do I copy files from a different folder into docker container’s working directory?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6cab9",
   "metadata": {},
   "source": [
    "Q5 Building a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7541bf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "QUESTION: How do I execute a command in a running docker container?\n",
      "\n",
      "CONTEXT:\n",
      "Q: How do I debug a docker container?\n",
      "A: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\n",
      "docker run -it --entrypoint bash <image>\n",
      "If the container is already running, execute a command in the specific container:\n",
      "docker ps (find the container-id)\n",
      "docker exec -it <container-id> bash\n",
      "(Marcos MJD)\n",
      "\n",
      "Q: How do I copy files from my local machine to docker container?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "To copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\n",
      "docker cp /path/to/local/file_or_directory container_id:/path/in/container\n",
      "Hrithik Kumar Advani\n",
      "\n",
      "Q: How do I copy files from a different folder into docker container’s working directory?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "In the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\n",
      "COPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\t\t\t\t\t\t\t\t\t\t\tGopakumar Gopinathan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1462"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    context_entries = []\n",
    "    context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    for record in search_results:\n",
    "        # print(\"Printing a record: \", record)\n",
    "        formatted_entry = context_template.format(question=record['question'], text=record['text'])\n",
    "        #print(\"Printing the formatted entry: \", formatted_entry)\n",
    "        context_entries.append(formatted_entry)\n",
    "\n",
    "    context = \"\\n\\n\".join(context_entries)\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "final_prompt = build_prompt(query, elastic_search_filtered(query))\n",
    "\n",
    "print(final_prompt)\n",
    "len(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62f07b",
   "metadata": {},
   "source": [
    "Answer 5: 1462"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9daed31",
   "metadata": {},
   "source": [
    "Q6 Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0824eb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/dmitry/Documents/Programming/Python/llm-zoomcamp/.venv/lib/python3.12/site-packages/')\n",
    "import tiktoken\n",
    "# Using tokenization algorithm for gpt-4o: https://community.openai.com/t/whats-the-new-tokenization-algorithm-for-gpt-4o/746708\n",
    "# encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = encoding.encode(final_prompt)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f1d8e",
   "metadata": {},
   "source": [
    "Answer 6: 322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b197235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Answer:\n",
      " To execute a command in a running Docker container, you can use the `docker exec` command. First, find the container ID by using `docker ps`. Then, execute the command in the specific container using the following syntax:\n",
      "\n",
      "```bash\n",
      "docker exec -it <container-id> <command>\n",
      "```\n",
      "\n",
      "For example, to start a bash session in the container, you would use:\n",
      "\n",
      "```bash\n",
      "docker exec -it <container-id> bash\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"openai/gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": final_prompt}\n",
    "    ],\n",
    "    temperature=0.3,\n",
    "    max_tokens=300  # limit output tokens so it's affordable\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(\"AI Answer:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ace14493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input tokens: 150000 → $0.75\n",
      "Total output tokens: 250000 → $3.75\n",
      " Total estimated cost for 1000 requests: $4.50\n"
     ]
    }
   ],
   "source": [
    "# Define values\n",
    "input_tokens_per_request = 150\n",
    "output_tokens_per_request = 250\n",
    "num_requests = 1000\n",
    "\n",
    "# Prices (as of June 17)\n",
    "input_price_per_1k = 0.005   # $ per 1000 input tokens\n",
    "output_price_per_1k = 0.015  # $ per 1000 output tokens\n",
    "\n",
    "# Total tokens\n",
    "total_input_tokens = input_tokens_per_request * num_requests\n",
    "total_output_tokens = output_tokens_per_request * num_requests\n",
    "\n",
    "# Total cost\n",
    "input_cost = (total_input_tokens / 1000) * input_price_per_1k\n",
    "output_cost = (total_output_tokens / 1000) * output_price_per_1k\n",
    "total_cost = input_cost + output_cost\n",
    "\n",
    "# Print breakdown\n",
    "print(f\"Total input tokens: {total_input_tokens} → ${input_cost:.2f}\")\n",
    "print(f\"Total output tokens: {total_output_tokens} → ${output_cost:.2f}\")\n",
    "print(f\" Total estimated cost for {num_requests} requests: ${total_cost:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "098ec273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Token usage:\n",
      "Input tokens per request: 325\n",
      "Output tokens per request: 92\n",
      "\n",
      " Estimated cost for 1000 requests:\n",
      "Total input tokens: 325000\n",
      "Total output tokens: 92000\n",
      "Input cost: $ 1.62\n",
      "Output cost: $ 1.38\n",
      "Total estimated cost: $ 3.0\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")  # GPT-4o uses same encoding as GPT-4 for now\n",
    "\n",
    "input_tokens = encoding.encode(final_prompt)\n",
    "output_tokens = encoding.encode(answer)\n",
    "\n",
    "num_input_tokens = len(input_tokens)\n",
    "num_output_tokens = len(output_tokens)\n",
    "\n",
    "print(\"\\n Token usage:\")\n",
    "print(\"Input tokens per request:\", num_input_tokens)\n",
    "print(\"Output tokens per request:\", num_output_tokens)\n",
    "\n",
    "#  Cost estimation\n",
    "price_per_1k_input = 0.005\n",
    "price_per_1k_output = 0.015\n",
    "num_requests = 1000\n",
    "\n",
    "total_input_tokens = num_input_tokens * num_requests\n",
    "total_output_tokens = num_output_tokens * num_requests\n",
    "\n",
    "input_cost = (total_input_tokens / 1000) * price_per_1k_input\n",
    "output_cost = (total_output_tokens / 1000) * price_per_1k_output\n",
    "total_cost = input_cost + output_cost\n",
    "\n",
    "print(\"\\n Estimated cost for 1000 requests:\")\n",
    "print(\"Total input tokens:\", total_input_tokens)\n",
    "print(\"Total output tokens:\", total_output_tokens)\n",
    "print(\"Input cost: $\", round(input_cost, 2))\n",
    "print(\"Output cost: $\", round(output_cost, 2))\n",
    "print(\"Total estimated cost: $\", round(total_cost, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
