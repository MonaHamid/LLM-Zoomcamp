{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86bcc522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Vector Search Homework Solutions ===\n",
      "\n",
      "Q1: Embedding the query\n",
      "Query embedding shape: (512,)\n",
      "Minimal value: -0.117\n",
      "Answer: -0.12\n",
      "\n",
      "Q2: Cosine similarity with another vector\n",
      "Cosine similarity: 0.901\n",
      "Answer: 0.9\n",
      "\n",
      "Q3: Ranking by cosine similarity (text only)\n",
      "Similarities: [0.76296847 0.81823782 0.81091955 0.7133079  0.73044992]\n",
      "Highest similarity document index: 1\n",
      "Answer: 1\n",
      "\n",
      "Q4: Ranking with concatenated text\n",
      "Similarities (full): [0.85145432 0.84365942 0.84177186 0.7755158  0.80860078]\n",
      "Highest similarity document index (full text): 0\n",
      "Answer: 0\n",
      "\n",
      "Q5: Selecting embedding model\n",
      "BAAI/bge-small-en dimension: 384\n",
      "Answer: 384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete homework\n",
    "import numpy as np\n",
    "from fastembed import TextEmbedding\n",
    "import requests\n",
    "\n",
    "print(\"=== Vector Search Homework Solutions ===\\n\")\n",
    "\n",
    "# Q1: Embedding the query\n",
    "print(\"Q1: Embedding the query\")\n",
    "model = TextEmbedding('jinaai/jina-embeddings-v2-small-en')\n",
    "query = 'I just discovered the course. Can I join now?'\n",
    "query_embedding = list(model.embed([query]))[0]\n",
    "\n",
    "print(f\"Query embedding shape: {query_embedding.shape}\")\n",
    "print(f\"Minimal value: {query_embedding.min():.3f}\")\n",
    "print(f\"Answer: {query_embedding.min():.2f}\\n\")\n",
    "\n",
    "# Q2: Cosine similarity\n",
    "print(\"Q2: Cosine similarity with another vector\")\n",
    "doc = 'Can I still join the course after the start date?'\n",
    "doc_embedding = list(model.embed([doc]))[0]\n",
    "cosine_similarity = np.dot(query_embedding, doc_embedding)\n",
    "print(f\"Cosine similarity: {cosine_similarity:.3f}\")\n",
    "print(f\"Answer: {cosine_similarity:.1f}\\n\")\n",
    "\n",
    "# Q3 & Q4: Documents\n",
    "documents = [\n",
    "    {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - Can I still join the course after the start date?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - Can I follow the course after it finishes?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  \\\"Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon't forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - When will the course start?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - What can I do before the course starts?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'How can we contribute to the course?',\n",
    "     'course': 'data-engineering-zoomcamp'}\n",
    "]\n",
    "\n",
    "# Q3: Ranking by cosine (text only)\n",
    "print(\"Q3: Ranking by cosine similarity (text only)\")\n",
    "texts = [doc['text'] for doc in documents]\n",
    "text_embeddings = list(model.embed(texts))\n",
    "V = np.array(text_embeddings)\n",
    "similarities = V.dot(query_embedding)\n",
    "highest_idx = np.argmax(similarities)\n",
    "print(f\"Similarities: {similarities}\")\n",
    "print(f\"Highest similarity document index: {highest_idx}\")\n",
    "print(f\"Answer: {highest_idx}\\n\")\n",
    "\n",
    "# Q4: Ranking with full text\n",
    "print(\"Q4: Ranking with concatenated text\")\n",
    "full_texts = [doc['question'] + ' ' + doc['text'] for doc in documents]\n",
    "full_text_embeddings = list(model.embed(full_texts))\n",
    "V_full = np.array(full_text_embeddings)\n",
    "similarities_full = V_full.dot(query_embedding)\n",
    "highest_idx_full = np.argmax(similarities_full)\n",
    "print(f\"Similarities (full): {similarities_full}\")\n",
    "print(f\"Highest similarity document index (full text): {highest_idx_full}\")\n",
    "print(f\"Answer: {highest_idx_full}\\n\")\n",
    "\n",
    "# Q5: Small embedding model\n",
    "print(\"Q5: Selecting embedding model\")\n",
    "small_model = TextEmbedding('BAAI/bge-small-en')\n",
    "test_embedding = list(small_model.embed([\"test\"]))[0]\n",
    "print(f\"BAAI/bge-small-en dimension: {test_embedding.shape[0]}\")\n",
    "print(f\"Answer: {test_embedding.shape[0]}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f554b8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6: Indexing with Qdrant (Memory Efficient)\n",
      "Found 375 ML documents\n",
      "Processing batch 1/8 (docs 0-49)\n",
      "Processing batch 2/8 (docs 50-99)\n",
      "Processing batch 3/8 (docs 100-149)\n",
      "Processing batch 4/8 (docs 150-199)\n",
      "Processing batch 5/8 (docs 200-249)\n",
      "Processing batch 6/8 (docs 250-299)\n",
      "Processing batch 7/8 (docs 300-349)\n",
      "Processing batch 8/8 (docs 350-374)\n",
      "All documents indexed successfully!\n",
      "Top result score: 0.87\n",
      "Answer: 0.87\n",
      "Result 1: Score 0.870\n",
      "Question: The course has already started. Can I still join it?...\n",
      "\n",
      "Result 2: Score 0.869\n",
      "Question: How long is the course?...\n",
      "\n",
      "Result 3: Score 0.868\n",
      "Question: I’m new to Slack and can’t find the course channel. Where is it?...\n",
      "\n",
      "Result 4: Score 0.858\n",
      "Question: How to get started with Week 10?...\n",
      "\n",
      "Result 5: Score 0.857\n",
      "Question: I just joined. What should I do next? How can I access course materials?...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5298/3944962052.py:69: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = client.search(\n"
     ]
    }
   ],
   "source": [
    "# Q6: Qdrant indexing\n",
    "# Q6: Memory-efficient Qdrant indexing\n",
    "print(\"Q6: Indexing with Qdrant (Memory Efficient)\")\n",
    "try:\n",
    "    from qdrant_client import QdrantClient\n",
    "    from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "    \n",
    "    # Download and process documents\n",
    "    docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "\n",
    "    ml_documents = []\n",
    "    for course in documents_raw:\n",
    "        if course['course'] == 'machine-learning-zoomcamp':\n",
    "            for doc in course['documents']:\n",
    "                doc['course'] = course['course']\n",
    "                ml_documents.append(doc)\n",
    "\n",
    "    print(f\"Found {len(ml_documents)} ML documents\")\n",
    "\n",
    "    # Set up Qdrant and index\n",
    "    client = QdrantClient(\":memory:\")\n",
    "    collection_name = \"ml_zoomcamp_faq\"\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=384, distance=Distance.COSINE)\n",
    "    )\n",
    "\n",
    "    # Process documents in smaller batches to avoid memory issues\n",
    "    batch_size = 50  # Process 50 documents at a time\n",
    "    total_batches = (len(ml_documents) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for batch_idx in range(total_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(ml_documents))\n",
    "        \n",
    "        print(f\"Processing batch {batch_idx + 1}/{total_batches} (docs {start_idx}-{end_idx-1})\")\n",
    "        \n",
    "        # Get batch of documents\n",
    "        batch_docs = ml_documents[start_idx:end_idx]\n",
    "        \n",
    "        # Prepare texts for embedding\n",
    "        batch_texts = [doc['question'] + ' ' + doc['text'] for doc in batch_docs]\n",
    "        \n",
    "        # Generate embeddings for this batch\n",
    "        batch_embeddings = list(small_model.embed(batch_texts))\n",
    "        \n",
    "        # Create points for this batch\n",
    "        batch_points = [\n",
    "            PointStruct(\n",
    "                id=start_idx + i, \n",
    "                vector=emb.tolist(), \n",
    "                payload=doc\n",
    "            )\n",
    "            for i, (doc, emb) in enumerate(zip(batch_docs, batch_embeddings))\n",
    "        ]\n",
    "        \n",
    "        # Insert batch into Qdrant\n",
    "        client.upsert(collection_name=collection_name, points=batch_points)\n",
    "        \n",
    "        # Clear variables to free memory\n",
    "        del batch_embeddings, batch_points, batch_texts\n",
    "    \n",
    "    print(\"All documents indexed successfully!\")\n",
    "\n",
    "    # Query\n",
    "    query_embedding_small = list(small_model.embed([query]))[0]\n",
    "    search_results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding_small.tolist(),\n",
    "        limit=5\n",
    "    )\n",
    "\n",
    "    print(f\"Top result score: {search_results[0].score:.2f}\")\n",
    "    print(f\"Answer: {search_results[0].score:.2f}\")\n",
    "    \n",
    "    # Show top results for verification\n",
    "    for i, result in enumerate(search_results):\n",
    "        print(f\"Result {i+1}: Score {result.score:.3f}\")\n",
    "        print(f\"Question: {result.payload['question'][:100]}...\")\n",
    "        print()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Qdrant not installed. Install with: pip install qdrant-client\")\n",
    "    print(\"Expected answer for Q6: around 0.77-0.87\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    print(\"This might be due to memory constraints. Try restarting the kernel and running just Q6.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
