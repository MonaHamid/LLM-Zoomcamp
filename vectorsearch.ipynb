{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a14d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size: 512\n",
      "Minimal value: -0.11726373885183883\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Define the query string\n",
    "query = 'I just discovered the course. Can I join now?'\n",
    "\n",
    "# Embed the query and immediately convert the generator to a list\n",
    "query_embedding = list(embedding_model.embed([query]))\n",
    "\n",
    "# Get the actual embedding vector (it's the first and only element in the list)\n",
    "q = query_embedding[0]\n",
    "\n",
    "# Check the size of the array (as mentioned in the question)\n",
    "print(f\"Embedding size: {q.shape[0]}\")\n",
    "\n",
    "# Find the minimal value in the array\n",
    "min_value = q.min()\n",
    "print(f\"Minimal value: {min_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f08b446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9008528895674548\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Re-using from Q1  ---\n",
    "embedding_model = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "query = 'I just discovered the course. Can I join now?'\n",
    "q = list(embedding_model.embed([query]))[0]\n",
    "# -------------------------\n",
    "\n",
    "# Define the new document string\n",
    "doc_text = 'Can I still join the course after the start date?'\n",
    "\n",
    "# Embed this new document and convert to a list\n",
    "#    The fix is on this line:\n",
    "doc_embedding = list(embedding_model.embed([doc_text]))[0]\n",
    "\n",
    "# Calculate the cosine similarity\n",
    "cosine_similarity = q.dot(doc_embedding)\n",
    "\n",
    "print(f\"Cosine similarity: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f301c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.76296847 0.81823782 0.71915905 0.72130621 0.73432863]\n",
      "Highest scoring document index: 1\n"
     ]
    }
   ],
   "source": [
    "# --- Re-using from Q1 ---\n",
    "embedding_model = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "query = 'I just discovered the course. Can I join now?'\n",
    "q = list(embedding_model.embed([query]))[0]\n",
    "# -------------------------\n",
    "\n",
    "#  The documents provided in the homework\n",
    "documents = [\n",
    "    {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "     'section': 'General course-related questions', 'question': 'Course - Can I still join the course after the start date?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "     'section': 'General course-related questions', 'question': 'Course - Can I follow the course after it finishes?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': \"The purpose of this document is to capture frequently asked technical questions...\",\n",
    "     'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'You can start by installing and setting up all the dependencies and requirements...',\n",
    "     'section': 'General course-related questions', 'question': 'Course - What can I do before the course starts?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'Star the repo! Share it with friends if you find it useful ❣️...',\n",
    "     'section': 'General course-related questions', 'question': 'How can we contribute to the course?', 'course': 'data-engineering-zoomcamp'}\n",
    "]\n",
    "\n",
    "# Extract only the 'text' field from each document\n",
    "texts = [doc['text'] for doc in documents]\n",
    "\n",
    "# Embed all the texts and convert the generator to a list\n",
    "#    The fix is on this line:\n",
    "text_embeddings = list(embedding_model.embed(texts))\n",
    "\n",
    "# Convert the list of embeddings into a single 2D numpy array (matrix V)\n",
    "V = np.array(text_embeddings)\n",
    "\n",
    "# Compute all cosine similarities\n",
    "scores = V.dot(q)\n",
    "\n",
    "# Find the index of the document with the highest score\n",
    "highest_scoring_index = np.argmax(scores)\n",
    "\n",
    "print(\"Scores:\", scores)\n",
    "print(f\"Highest scoring document index: {highest_scoring_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b4386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores (full text): [0.85145432 0.84365942 0.822636   0.802103   0.83453303]\n",
      "Highest scoring document index (full text): 0\n"
     ]
    }
   ],
   "source": [
    "# --- Re-using from Q1 ---\n",
    "embedding_model = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "query = 'I just discovered the course. Can I join now?'\n",
    "q = list(embedding_model.embed([query]))[0]\n",
    "documents = [ # same documents as Q3\n",
    "    {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "     'section': 'General course-related questions', 'question': 'Course - Can I still join the course after the start date?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "     'section': 'General course-related questions', 'question': 'Course - Can I follow the course after it finishes?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': \"The purpose of this document is to capture frequently asked technical questions...\",\n",
    "     'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'You can start by installing and setting up all the dependencies and requirements...',\n",
    "     'section': 'General course-related questions', 'question': 'Course - What can I do before the course starts?', 'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'Star the repo! Share it with friends if you find it useful ❣️...',\n",
    "     'section': 'General course-related questions', 'question': 'How can we contribute to the course?', 'course': 'data-engineering-zoomcamp'}\n",
    "]\n",
    "# -----------------------------\n",
    "\n",
    "# Create a new list of texts by concatenating 'question' and 'text'\n",
    "full_texts = [f\"{doc['question']} {doc['text']}\" for doc in documents]\n",
    "\n",
    "# Embed these new combined texts and convert to a list\n",
    "#    The fix is on this line:\n",
    "full_text_embeddings = list(embedding_model.embed(full_texts))\n",
    "\n",
    "# Create the new matrix\n",
    "V_full = np.array(full_text_embeddings)\n",
    "\n",
    "# Compute the scores against the same query vector q\n",
    "scores_full = V_full.dot(q)\n",
    "\n",
    "# Find the new highest scoring index\n",
    "highest_scoring_index_full = np.argmax(scores_full)\n",
    "\n",
    "print(\"Scores (full text):\", scores_full)\n",
    "print(f\"Highest scoring document index (full text): {highest_scoring_index_full}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807f396",
   "metadata": {},
   "source": [
    "The input text for Q4 is different from the input text for Q3. Since the text is different, the embedding model creates a different vector. Because the vector is different, its cosine similarity to the query vector is also different.\n",
    "Let's break that down in more detail.\n",
    "The Core Concept: Embeddings Capture Meaning of the Entire Input\n",
    "Think of an embedding model (like jinaai/jina-embeddings-v2-small-en) as a highly sophisticated machine that reads a piece of text and converts its total meaning into a single point in a high-dimensional space. This point is the vector.\n",
    "This machine doesn't just look at individual words. It looks at the words in order, their relationships, and the overall context to produce the final vector.\n",
    "Any change to the input text, no matter how small, will change the final vector.\n",
    "Let's Use a Simple Analogy\n",
    "Imagine you're giving instructions to a painter, and the \"painting\" is the final vector.\n",
    "Instruction for Q3: You tell the painter, \"Paint a picture of 'Yes, even if you don't register, you're still eligible to submit the homeworks...'\". The painter creates Painting A, which captures the idea of \"eligibility\" and \"deadlines.\"\n",
    "Instruction for Q4: You tell the painter, \"Paint a picture of 'Course - Can I still join the course after the start date? Yes, even if you don't register...'\". The painter creates Painting B. This painting is different! It still has the concepts of \"eligibility\" and \"deadlines,\" but now it's framed by the much stronger context of \"joining a course late.\"\n",
    "Painting A and Painting B will be similar, but they are not identical.\n",
    "Why are the Scores Higher in Q4?\n",
    "Now, let's bring in your query: 'I just discovered the course. Can I join now?'.\n",
    "Think of this query as a reference painting, Painting Q. The cosine similarity score is a measure of how similar the other paintings are to this reference painting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e55a52f",
   "metadata": {},
   "source": [
    "Question 5: Selecting the embedding model\n",
    "Objective: Find the smallest embedding dimensionality available in fastembed.\n",
    "Step-by-step Code:\n",
    "We can use a built-in method from the TextEmbedding class to list all supported models and their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75cd6707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest dimensionality available is: 384\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "# Get the list of all supported models\n",
    "# This returns a list of dictionaries, each describing a model\n",
    "models_info = TextEmbedding.list_supported_models()\n",
    "\n",
    "# Extract the 'dim' (dimensionality) from each model's info\n",
    "all_dims = [model['dim'] for model in models_info]\n",
    "\n",
    "# Find the minimum value in the list of dimensions\n",
    "smallest_dim = min(all_dims)\n",
    "\n",
    "print(f\"The smallest dimensionality available is: {smallest_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b896ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents for ML Zoomcamp: 375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5606/3121601405.py:27: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest score is: 0.8703173398971558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5606/3121601405.py:60: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_results = client.search(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "# Download and filter documents (no change here)\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name == 'machine-learning-zoomcamp':\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            documents.append(doc)\n",
    "\n",
    "print(f\"Number of documents for ML Zoomcamp: {len(documents)}\")\n",
    "\n",
    "# Initialize the smaller embedding model\n",
    "embedding_model = TextEmbedding(model_name=\"BAAI/bge-small-en\")\n",
    "\n",
    "#  Initialize the Qdrant client\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create the Qdrant collection\n",
    "client.recreate_collection(\n",
    "    collection_name=\"ml_zoomcamp_faq\",\n",
    "    vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    ")\n",
    "\n",
    "#  Prepare the data for upserting\n",
    "points_to_upsert = []\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    \n",
    "    # FIX #1 is on this line:\n",
    "    embedding = list(embedding_model.embed([text]))[0]\n",
    "    \n",
    "    point = models.PointStruct(\n",
    "        id=i + 1,\n",
    "        vector=embedding.tolist(),\n",
    "        payload=doc\n",
    "    )\n",
    "    points_to_upsert.append(point)\n",
    "\n",
    "# Upsert all the points to the collection\n",
    "client.upsert(\n",
    "    collection_name=\"ml_zoomcamp_faq\",\n",
    "    points=points_to_upsert,\n",
    "    wait=True\n",
    ")\n",
    "\n",
    "# Prepare and embed the search query\n",
    "query = 'I just discovered the course. Can I join now?'\n",
    "# FIX #2 is on this line:\n",
    "query_vector = list(embedding_model.embed([query]))[0]\n",
    "\n",
    "# Perform the search in Qdrant\n",
    "search_results = client.search(\n",
    "    collection_name=\"ml_zoomcamp_faq\",\n",
    "    query_vector=query_vector,\n",
    "    limit=1\n",
    ")\n",
    "\n",
    "# Get the score of the highest-ranking result\n",
    "highest_score = search_results[0].score\n",
    "print(f\"The highest score is: {highest_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
